{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# ÂèÇÊï∞‰ºòÂåñ‰πãË¥ùÂè∂ÊñØ‰ºòÂåñÁÆóÊ≥ï"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">  \n",
    " <b>Version:</b> v0.1 <b>Date:</b> 2020-06-09\n",
    "  \n",
    "Âú®Ëøô‰∏™Notebook‰∏≠ÔºåËÆ∞ÂΩï‰∫ÜË¥ùÂè∂ÊñØÂèÇÊï∞ÊêúÁ¥¢ÁöÑÂÆûÁé∞Á≠ñÁï•„ÄÇ\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>üí°:</b> \n",
    "\n",
    "- **ÁéØÂ¢É‰æùËµñ**Ôºö Fastai v2 (0.0.18), BayesianOptimization\n",
    "- **Êï∞ÊçÆÈõÜ**Ôºö[ADULT_SAMPLE](http://files.fast.ai/data/examples/adult_sample.tgz) \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Êï∞ÊçÆÂáÜÂ§á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "gdhR8Lo7IgWr"
   },
   "outputs": [],
   "source": [
    "from fastai2.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "-MqaliygIgWt",
    "outputId": "a3bbf6a1-a795-450d-9930-5fdcb4fd2690"
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "y_names = 'salary'\n",
    "y_block = CategoryBlock()\n",
    "splits = RandomSplitter()(range_of(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "to = TabularPandas(df, procs=procs, cat_names=cat_names, cont_names=cont_names,\n",
    "                   y_names=y_names, y_block=y_block, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dls = to.dataloaders(bs=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## ÈÖçÁΩÆ‰ºòÂåñÁÆóÊ≥ï‰∏éÊêúÁ¥¢Á≠ñÁï•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "!pip install bayesian-optimization -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "eijUmw5hIgWy"
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "atUpeYC-IgW1"
   },
   "outputs": [],
   "source": [
    "def fit_with(lr:float, wd:float, dp:float):\n",
    "  # create a Learner\n",
    "  config = tabular_config(embed_p=dp, ps=wd)\n",
    "  learn = tabular_learner(data, layers=[200,100], metrics=accuracy, config=config)\n",
    "  \n",
    "  # Train for x epochs\n",
    "  with learn.no_bar():\n",
    "    learn.fit_one_cycle(3, lr)\n",
    "    \n",
    "  # Save, print, and return the overall accuracy\n",
    "  acc = float(learn.validate()[1])\n",
    "  \n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "p--GviyJIgW3"
   },
   "source": [
    "Let's adjust this further to show how we would go about adjusting the learning rate, embedded weight decay, drop out, and layer size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "NcluMNyjIgW4"
   },
   "outputs": [],
   "source": [
    "def fit_with(lr:float, wd:float, dp:float, n_layers:float, layer_1:float, layer_2:float, layer_3:float):\n",
    "\n",
    "  print(lr, wd, dp)\n",
    "  if int(n_layers) == 2:\n",
    "    layers = [int(layer_1), int(layer_2)]\n",
    "  elif int(n_layers) == 3:\n",
    "    layers = [int(layer_1), int(layer_2), int(layer_3)]\n",
    "  else:\n",
    "    layers = [int(layer_1)]\n",
    "  config = tabular_config(embed_p=float(dp),\n",
    "                          ps=float(wd))\n",
    "  learn = tabular_learner(dls, layers=layers, metrics=accuracy, config = config)\n",
    "\n",
    "  with learn.no_bar() and learn.no_logging():\n",
    "    learn.fit(5, lr=float(lr))\n",
    "\n",
    "  acc = float(learn.validate()[1])\n",
    "\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "wcsA4CNCIgW6"
   },
   "source": [
    "Let's try it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "WQPTuTjyIgXB"
   },
   "source": [
    "We'll declare our hyper-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "_H3QggARIgXB"
   },
   "outputs": [],
   "source": [
    "hps = {'lr': (1e-05, 1e-01),\n",
    "      'wd': (4e-4, 0.4),\n",
    "      'dp': (0.01, 0.5),\n",
    "       'n_layers': (1,3),\n",
    "       'layer_1': (50, 200),\n",
    "       'layer_2': (100, 1000),\n",
    "       'layer_3': (200, 2000)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "UZ0MnAl4IgXD"
   },
   "source": [
    "And now we build the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "P2-kaaX5IgXD"
   },
   "outputs": [],
   "source": [
    "optim = BayesianOptimization(\n",
    "    f = fit_with, # our fit function\n",
    "    pbounds = hps, # our hyper parameters to tune\n",
    "    verbose = 2, # 1 prints out when a maximum is observed, 0 for silent\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "ggjvIx9SIgXF"
   },
   "source": [
    "And now we can search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "uWIPvNZFIgXF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    dp     |  layer_1  |  layer_2  |  layer_3  |    lr     | n_layers  |    wd     |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "0.014684121522803134 0.07482958046651729 0.21434078230426126\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8415  \u001b[0m | \u001b[0m 0.2143  \u001b[0m | \u001b[0m 158.0   \u001b[0m | \u001b[0m 100.1   \u001b[0m | \u001b[0m 744.2   \u001b[0m | \u001b[0m 0.01468 \u001b[0m | \u001b[0m 1.185   \u001b[0m | \u001b[0m 0.07483 \u001b[0m |\n",
      "0.06852509784467198 0.3512957275818218 0.1793247562510934\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8391  \u001b[0m | \u001b[0m 0.1793  \u001b[0m | \u001b[0m 109.5   \u001b[0m | \u001b[0m 584.9   \u001b[0m | \u001b[0m 954.6   \u001b[0m | \u001b[0m 0.06853 \u001b[0m | \u001b[0m 1.409   \u001b[0m | \u001b[0m 0.3513  \u001b[0m |\n",
      "0.014047289990137426 0.32037752964274446 0.02341992066698382\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8383  \u001b[0m | \u001b[0m 0.02342 \u001b[0m | \u001b[0m 150.6   \u001b[0m | \u001b[0m 475.6   \u001b[0m | \u001b[0m 1.206e+0\u001b[0m | \u001b[0m 0.01405 \u001b[0m | \u001b[0m 1.396   \u001b[0m | \u001b[0m 0.3204  \u001b[0m |\n",
      "0.0894617202837497 0.016006291379859792 0.4844481721025048\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8395  \u001b[0m | \u001b[0m 0.4844  \u001b[0m | \u001b[0m 97.01   \u001b[0m | \u001b[0m 723.1   \u001b[0m | \u001b[0m 1.778e+0\u001b[0m | \u001b[0m 0.08946 \u001b[0m | \u001b[0m 1.17    \u001b[0m | \u001b[0m 0.01601 \u001b[0m |\n",
      "0.0957893741197487 0.27687409473460917 0.09321690558663875\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.8426  \u001b[0m | \u001b[95m 0.09322 \u001b[0m | \u001b[95m 181.7   \u001b[0m | \u001b[95m 188.5   \u001b[0m | \u001b[95m 958.0   \u001b[0m | \u001b[95m 0.09579 \u001b[0m | \u001b[95m 2.066   \u001b[0m | \u001b[95m 0.2769  \u001b[0m |\n",
      "0.06191147756969865 0.37690994180463505 0.13594244704069394\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8345  \u001b[0m | \u001b[0m 0.1359  \u001b[0m | \u001b[0m 58.72   \u001b[0m | \u001b[0m 121.5   \u001b[0m | \u001b[0m 1.958e+0\u001b[0m | \u001b[0m 0.06191 \u001b[0m | \u001b[0m 1.277   \u001b[0m | \u001b[0m 0.3769  \u001b[0m |\n",
      "0.03866826261417955 0.16855031040289803 0.4601228621079202\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8395  \u001b[0m | \u001b[0m 0.4601  \u001b[0m | \u001b[0m 199.1   \u001b[0m | \u001b[0m 977.2   \u001b[0m | \u001b[0m 223.7   \u001b[0m | \u001b[0m 0.03867 \u001b[0m | \u001b[0m 1.036   \u001b[0m | \u001b[0m 0.1686  \u001b[0m |\n",
      "0.0243344917906167 0.3026399240336963 0.10573854076050722\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8398  \u001b[0m | \u001b[0m 0.1057  \u001b[0m | \u001b[0m 180.7   \u001b[0m | \u001b[0m 272.5   \u001b[0m | \u001b[0m 977.7   \u001b[0m | \u001b[0m 0.02433 \u001b[0m | \u001b[0m 1.126   \u001b[0m | \u001b[0m 0.3026  \u001b[0m |\n",
      "0.01926217459495932 0.09147910397966807 0.12524115091042773\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8391  \u001b[0m | \u001b[0m 0.1252  \u001b[0m | \u001b[0m 57.32   \u001b[0m | \u001b[0m 188.9   \u001b[0m | \u001b[0m 206.0   \u001b[0m | \u001b[0m 0.01926 \u001b[0m | \u001b[0m 2.35    \u001b[0m | \u001b[0m 0.09148 \u001b[0m |\n",
      "0.018285009041055747 0.0030016178873130826 0.023091032083187666\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8417  \u001b[0m | \u001b[0m 0.02309 \u001b[0m | \u001b[0m 182.3   \u001b[0m | \u001b[0m 997.6   \u001b[0m | \u001b[0m 1.941e+0\u001b[0m | \u001b[0m 0.01829 \u001b[0m | \u001b[0m 2.989   \u001b[0m | \u001b[0m 0.003002\u001b[0m |\n",
      "0.016475919398227245 0.02899527328407459 0.35565211893540777\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.8437  \u001b[0m | \u001b[95m 0.3557  \u001b[0m | \u001b[95m 197.2   \u001b[0m | \u001b[95m 126.1   \u001b[0m | \u001b[95m 264.7   \u001b[0m | \u001b[95m 0.01648 \u001b[0m | \u001b[95m 2.714   \u001b[0m | \u001b[95m 0.029   \u001b[0m |\n",
      "0.0758754095037137 0.26350352166402036 0.10013698396219092\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8371  \u001b[0m | \u001b[0m 0.1001  \u001b[0m | \u001b[0m 195.5   \u001b[0m | \u001b[0m 166.4   \u001b[0m | \u001b[0m 236.0   \u001b[0m | \u001b[0m 0.07588 \u001b[0m | \u001b[0m 1.276   \u001b[0m | \u001b[0m 0.2635  \u001b[0m |\n",
      "0.08706685388671734 0.2815475542319707 0.0263005243239511\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8401  \u001b[0m | \u001b[0m 0.0263  \u001b[0m | \u001b[0m 199.1   \u001b[0m | \u001b[0m 990.5   \u001b[0m | \u001b[0m 1.991e+0\u001b[0m | \u001b[0m 0.08707 \u001b[0m | \u001b[0m 2.941   \u001b[0m | \u001b[0m 0.2815  \u001b[0m |\n",
      "0.05628262681087503 0.1085257299138718 0.26772478114338355\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8404  \u001b[0m | \u001b[0m 0.2677  \u001b[0m | \u001b[0m 152.2   \u001b[0m | \u001b[0m 105.5   \u001b[0m | \u001b[0m 755.5   \u001b[0m | \u001b[0m 0.05628 \u001b[0m | \u001b[0m 2.52    \u001b[0m | \u001b[0m 0.1085  \u001b[0m |\n",
      "0.0604172099015805 0.11754051701232375 0.4265112940023884\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8391  \u001b[0m | \u001b[0m 0.4265  \u001b[0m | \u001b[0m 198.0   \u001b[0m | \u001b[0m 995.7   \u001b[0m | \u001b[0m 1.118e+0\u001b[0m | \u001b[0m 0.06042 \u001b[0m | \u001b[0m 1.485   \u001b[0m | \u001b[0m 0.1175  \u001b[0m |\n",
      "=============================================================================================================\n",
      "CPU times: user 1min 2s, sys: 37.4 s, total: 1min 39s\n",
      "Wall time: 51.7 s\n"
     ]
    }
   ],
   "source": [
    "%time optim.maximize(n_iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "memBJ-W_IgXI"
   },
   "source": [
    "We can grab the best results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "h31R57UZIgXI",
    "outputId": "4c71d308-b7aa-43a7-d45e-04e40030af3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0.8436732292175293, 'params': {'dp': 0.35565211893540777, 'layer_1': 197.225429657967, 'layer_2': 126.14266384474438, 'layer_3': 264.66132182791586, 'lr': 0.016475919398227245, 'n_layers': 2.7135113787445775, 'wd': 0.02899527328407459}}\n"
     ]
    }
   ],
   "source": [
    "print(optim.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "1GqnPXX2IgXK"
   },
   "source": [
    "And with a few conversions we see:\n",
    "\n",
    "* The best number of layers was 2\n",
    "* The first layer a size of 57\n",
    "* The second layer a size of 100\n",
    "And then of course our other hyper paramters"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "02_Bayesian_Optimization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "FastAi2",
   "language": "python",
   "name": "fastai2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
